{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Pattern Recognition - Machine Learning** | Assignment 2\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pzWFLo8HInnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1) Face Recognition**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hKzW8Erhgxop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ul1mcvP7pPCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **I) Image Loading and Sets creation**"
      ],
      "metadata": {
        "id": "ttDTiRWPhXtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Define path\n",
        "path = '/content/drive/MyDrive/faces'\n",
        "\n",
        "# Ranges for separating images based on the selection pattern\n",
        "set_ranges = {\n",
        "    'Set_1': (1, 7),\n",
        "    'Set_2': (8, 19),\n",
        "    'Set_3': (20, 31),\n",
        "    'Set_4': (32, 45),\n",
        "    'Set_5': (46, 64)\n",
        "}\n",
        "\n",
        "# Function for loading images and storing them in an array\n",
        "def Load_Images(path, set_number):\n",
        "\n",
        "    # Printing format\n",
        "    print(\"\\n-----------------------------------\", set_number, \"-----------------------------------\\n\")\n",
        "    (start, end) = set_ranges[set_number]\n",
        "    columns = 10*(end-start+1)\n",
        "    groups = end-start+1\n",
        "    values = 2500\n",
        "    total_images = 640\n",
        "\n",
        "    # Initialize the image array (2500 rows, 70 columns)\n",
        "    image_array = np.zeros((values, columns))\n",
        "\n",
        "    current_column = 0\n",
        "    image_paths = []\n",
        "    image_name = []\n",
        "    labels = []\n",
        "\n",
        "    # Find images based on the specified pattern\n",
        "    for person in range(10):\n",
        "        for i in range(start, end+1):\n",
        "\n",
        "            # Create file name based on the acquire pattern\n",
        "            image_pattern = f\"person{person+1:02d}_{i:02d}.png\"\n",
        "            full_path = path + \"/\" + image_pattern\n",
        "            image_paths.append(full_path)\n",
        "            image_name.append(image_pattern)\n",
        "\n",
        "    person = 0\n",
        "    current_column = 0\n",
        "\n",
        "    # Find and print images by category and in the order defined by the acquire pattern\n",
        "    k = 0\n",
        "    for full_path in image_paths:\n",
        "\n",
        "        if (current_column % groups == 0):\n",
        "          person += 1\n",
        "          print(\"\\n____________ Images of person\", person, \"____________\\n\")\n",
        "\n",
        "        labels.append(person)\n",
        "        image = cv2.imread(full_path, 0)\n",
        "\n",
        "        # Read image with OpenCV\n",
        "        print(image_name[k], \" | shape\", image.shape)\n",
        "        if image is not None:\n",
        "          plt.imshow(image, cmap='bone')\n",
        "          plt.show()\n",
        "        else:\n",
        "          print(\"Failed to read the image.\")\n",
        "\n",
        "        # Transform the image into a column vector\n",
        "        flattened_image = image.reshape(-1, 1)\n",
        "\n",
        "        # Store the image vector as a column in the image array of each 'image set'\n",
        "        image_array[:, current_column] = flattened_image.flatten()\n",
        "\n",
        "        # Counter and column update\n",
        "        current_column += 1\n",
        "        k += 1\n",
        "\n",
        "    # Return the array of the corresponding set of images\n",
        "    return [image_array, labels]\n",
        "\n",
        "# Define and format the names of the arrays\n",
        "(start, end) = set_ranges['Set_1']\n",
        "columns = 10*(end-start+1)\n",
        "Set_1 = np.zeros((2500, columns))\n",
        "\n",
        "(start, end) = set_ranges['Set_2']\n",
        "columns = 10*(end-start+1)\n",
        "Set_2 = np.zeros((2500, columns))\n",
        "\n",
        "(start, end) = set_ranges['Set_3']\n",
        "columns = 10*(end-start+1)\n",
        "Set_3 = np.zeros((2500, columns))\n",
        "\n",
        "(start, end) = set_ranges['Set_4']\n",
        "columns = 10*(end-start+1)\n",
        "Set_4 = np.zeros((2500, columns))\n",
        "\n",
        "(start, end) = set_ranges['Set_5']\n",
        "columns = 10*(end-start+1)\n",
        "Set_5 = np.zeros((2500, columns))\n",
        "\n",
        "# Function calls\n",
        "Set_1 = Load_Images(path, 'Set_1')[0]\n",
        "labels_1 = Load_Images(path, 'Set_1')[1]\n",
        "Set_2 = Load_Images(path, 'Set_2')[0]\n",
        "labels_2 = Load_Images(path, 'Set_2')[1]\n",
        "Set_3 = Load_Images(path, 'Set_3')[0]\n",
        "labels_3 = Load_Images(path, 'Set_3')[1]\n",
        "Set_4 = Load_Images(path, 'Set_4')[0]\n",
        "labels_4 = Load_Images(path, 'Set_4')[1]\n",
        "Set_5 = Load_Images(path, 'Set_5')[0]\n",
        "labels_5 = Load_Images(path, 'Set_5')[1]"
      ],
      "metadata": {
        "id": "plS5o-1dhtkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **II) Eigenfaces method training on Set_1 and face recognition trial for the other Sets**"
      ],
      "metadata": {
        "id": "xJSCbMLojl46"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Training set\n",
        "train_set = Set_1\n",
        "\n",
        "# Create lists for better data retrieval in the following loops\n",
        "d_values = [9, 30]\n",
        "accuracy_scores = []\n",
        "sets_labels = [labels_1, labels_2, labels_3, labels_4, labels_5]\n",
        "test_sets = [Set_1, Set_2, Set_3, Set_4, Set_5]\n",
        "\n",
        "print(\"\\n----------------------- Accuracy Scores for PCA Eigenfaces with KNN classifier -----------------------\\n\")\n",
        "\n",
        "# For d=9 and d=30\n",
        "for d in d_values:\n",
        "\n",
        "    # Apply PCA to the training set\n",
        "    pca = PCA(n_components=d)\n",
        "    transformed_data = pca.fit_transform(train_set.T)\n",
        "\n",
        "    # Find the Eigenfaces\n",
        "    eigenfaces = pca.components_.T\n",
        "\n",
        "    # Project the Training data onto the Eigenfaces\n",
        "    training_data = transformed_data\n",
        "\n",
        "    # K-nearest neighbors classifier\n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "    # Define and fit the K-nearest neighbors classifier\n",
        "    knn = KNeighborsClassifier(n_neighbors=3)\n",
        "    knn.fit(training_data, labels_1)\n",
        "\n",
        "    # Evaluate the model on Set_1 to Set_5\n",
        "    for i, test_set in enumerate(test_sets):\n",
        "\n",
        "        # Apply PCA to each test Set using the same Eigenfaces\n",
        "        transformed_test_set = pca.transform(test_set.T)\n",
        "\n",
        "        # Use the trained model to predict the image category\n",
        "        predicted_labels = knn.predict(transformed_test_set)\n",
        "\n",
        "        # Calculate the accuracy of the model on each Set\n",
        "        accuracy = accuracy_score(sets_labels[i], predicted_labels)\n",
        "        accuracy_scores.append(accuracy)\n",
        "        print(f\"Accuracy for Set_{i+1} with d={d}: {accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "lKfkkQtlj1Lv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that the model has a decreasing percentage of successful classification/matching of images to the corresponding person as we move from one Set_i to Set_(i+1). This is due to the fact that each image Set differs from the others, for example, in terms of lighting, image clarity, facial line characteristics, and other features. Thus, each dataset matrix contains different density and quality of information that the model can leverage, resulting in the generalization of the method being less effective across all image Sets. We notice that for Set_1, which is our training set, the accuracy is 100%, which is expected since the model was initially trained on it."
      ],
      "metadata": {
        "id": "wsKKpNxDlfVh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **III) Visualization of Eigenvectors of the trained model**\n",
        "\n"
      ],
      "metadata": {
        "id": "BJLVUGe1uW5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot values και specs\n",
        "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
        "\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    eigenvector = eigenfaces[:, i]\n",
        "    ax.imshow(eigenvector.reshape(50, 50), cmap='gray')\n",
        "    ax.set_title(f\"Eigenvector {i+1}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y0W3JCm2wE9G",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 9 main eigenfaces that resulted from the PCA analysis represent the most significant patterns/features of the training images. Each eigenface is an eigenvector of the covariance matrix calculated from the training image dataset.\n",
        "\n",
        "Eigenfaces capture the dominant variations in values present in face images. They essentially reflect a subset of the face data, such as lighting conditions, facial expressions, and different facial features (e.g., eyes, nose, mouth, lips, angles, etc.). This subset of data is, in a sense, characteristic and unique to each individual's face, aiding the model in identifying and recognizing other images belonging to the test sets.\n",
        "\n",
        "The first eigenface (eigenvector) corresponds to the largest eigenvalue and captures the most prominent variation of characteristics in the face images. It is equivalent to the average shape of the dataset, representing the mean facial features present in all faces. Each subsequent eigenface shows a different data structure for the same qualitative characteristics (e.g., lighting, angles, dark colors, eyes, mouth, etc.), indicating varying degrees/levels of deviation compared to the dominant eigenface 1. In fact, upon careful observation of the eigenfaces, we can say that the first face is the most distinct from the rest. The faces 4-5-6 and 7-8-9 resemble each other more as trios, just like the pair 2-3.\n",
        "\n",
        "In summary, the 9 main eigenfaces indicate the most important differences in face images, capturing the fundamental patterns that distinguish one face from another."
      ],
      "metadata": {
        "id": "hfkwu-YEdLOS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IV) Face image recreation through Eigenfaces**"
      ],
      "metadata": {
        "id": "zKKDZgBf5FaF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for image reconstruction based on Eigenfaces\n",
        "def recreate_image(eigenfaces, coefficients):\n",
        "  mean_face = np.mean(train_set.T, axis=0)\n",
        "  return mean_face + np.dot(coefficients, eigenfaces.T)\n",
        "\n",
        "# For d=9 and d=30\n",
        "for d in d_values:\n",
        "\n",
        "  # Evaluation of the model on Set_1 to Set_5\n",
        "  for i, test_set in enumerate(test_sets):\n",
        "\n",
        "      # Randomly select an image from the test Set\n",
        "      random_index = np.random.choice(test_set.shape[1])\n",
        "      selected_image = test_set[:, random_index]\n",
        "\n",
        "      # Reconstruct the image using Eigenfaces\n",
        "      reconstructed_image = recreate_image(eigenfaces, transformed_test_set[random_index])\n",
        "\n",
        "      # Reshaping images for plotting\n",
        "      selected_image = selected_image.reshape(50, 50)\n",
        "      reconstructed_image = reconstructed_image.reshape(50, 50)\n",
        "\n",
        "      # Plotting the original and approximately reconstructed images\n",
        "\n",
        "      # Original\n",
        "      plt.figure()\n",
        "      plt.subplot(1, 2, 1)\n",
        "      plt.imshow(selected_image, cmap='gray')\n",
        "      plt.title(f\"Original Image (Set_{i+1})\")\n",
        "      plt.axis(\"off\")\n",
        "\n",
        "      # Reconstructed\n",
        "      plt.subplot(1, 2, 2)\n",
        "      plt.imshow(reconstructed_image, cmap='gray')\n",
        "      plt.title(f\"Reconstructed Image (Set_{i+1}, d={d})\")\n",
        "      plt.axis(\"off\")\n",
        "\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "aCAhBTDL5RrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that for d=9, the effectiveness of image reconstruction is lower compared to d=30. This is logical because in the first case, the dimensionality of the data is lower, so the model has fewer elements available to capture the true structure of the image it is trying to approximate. For d=30, its effectiveness increases.\n",
        "\n",
        "Additionally, we can see that when the facial image is quite dark and not many lines and facial features are discernible, the model performs significantly better for d=30 compared to d=9. This can be explained by the fact that for d=30, it has more data available to predict/reconstruct the genuine image, even with significant missing elements (e.g., dark areas, lack of lines, etc.)."
      ],
      "metadata": {
        "id": "VVXMToair5VL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **V) Depiction of Eigenvectors with SVD pre-processing**"
      ],
      "metadata": {
        "id": "ZgK7jALZ7GqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply SVD on training Set 'Set_1'\n",
        "U, s, V = np.linalg.svd(Set_1)\n",
        "\n",
        "# Select the first 9 singular vectors\n",
        "main_singular_vectors = U[:, :9]\n",
        "\n",
        "# Plotting of the first 9 singular vectors\n",
        "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Images plotting\n",
        "for i, ax in enumerate(axes):\n",
        "    singular_vector = main_singular_vectors[:, i]\n",
        "    # Images reshaping\n",
        "    image = singular_vector.reshape(50, 50)\n",
        "    ax.imshow(image, cmap='gray')\n",
        "    ax.set_title(f\"Singular Vector {i+1}\")\n",
        "\n",
        "# Subplots spacing\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MrGZupPb7G9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eigenvectors and singular vectors differ due to the different computational approaches used to calculate them.\n",
        "\n",
        "- Eigenvectors, generated by PCA, indicate the axes of the n-dimensional space where the most variability/diversity of the data is observed. Therefore, these axes/dimensions are the ones utilized by the model to recognize patterns and faces in subsequent analysis.\n",
        "\n",
        "- On the other hand, singular vectors, produced by SVD, represent the relationship between the rows and columns of the matrices storing the image data.\n",
        "\n",
        "In general, the choice between eigenvectors and singular vectors depends on the nature of the data and the problem we are trying to solve."
      ],
      "metadata": {
        "id": "fJhS5-BOZ58U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2) Image classification using SVMs**"
      ],
      "metadata": {
        "id": "1Ob0j-v5CLyN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Data acquiring και normalization"
      ],
      "metadata": {
        "id": "y8QZKsvhc6dX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# MNIST dataset\n",
        "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "\n",
        "# Get image data and labels\n",
        "X = mnist['data']\n",
        "y = mnist['target']\n",
        "\n",
        "# Image conversion into 28x28 vectors\n",
        "X = X.values.reshape(-1, 28, 28)\n",
        "\n",
        "# Normalize data in [0, 1]\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X.reshape(-1, 28*28))\n",
        "\n",
        "# Select the frst 30000 samples for the training set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X[:30000], y[:30000], test_size=10000, random_state=42)\n",
        "\n",
        "# Save the training and testing sets\n",
        "np.savez('mnist_train.npz', X_train=X_train, y_train=y_train)\n",
        "np.savez('mnist_test.npz', X_test=X_test, y_test=y_test)"
      ],
      "metadata": {
        "id": "6gRVw4eHXVJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Training and comparative evaluation of linear SVM kernel and RBF kernel with combinations of hyperparameters."
      ],
      "metadata": {
        "id": "oS-BTpH2c5_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Search parameters\n",
        "param_grid = [\n",
        "    {'kernel': ['linear'], 'C': [0.1, 1, 10]},\n",
        "    {'kernel': ['rbf'], 'C': [0.1, 1, 10], 'gamma': [0.1, 0.01, 0.001]}\n",
        "]\n",
        "\n",
        "# SVM classifier init\n",
        "svm = SVC()\n",
        "\n",
        "# grid search\n",
        "grid_search = GridSearchCV(svm, param_grid, scoring='accuracy')\n",
        "\n",
        "# data fitting\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Find the best model and parameters for the Training Set\n",
        "best_model = grid_search.best_estimator_\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Results printing\n",
        "print(\"Results for Training Set:\")\n",
        "print(\"========================\")\n",
        "for params, mean_score, std_score in zip(grid_search.cv_results_['params'], grid_search.cv_results_['mean_test_score'], grid_search.cv_results_['std_test_score']):\n",
        "    print(\"Kernel: {}, C: {}, Gamma: {}\".format(params['kernel'], params['C'], params.get('gamma', 'N/A')))\n",
        "    print(\"Accuracy: {:.2f}% (+/- {:.2f}%)\".format(mean_score * 100, std_score * 100))\n",
        "    print()\n",
        "\n",
        "# Find the best model and parameters for the Training Set\n",
        "y_train_pred = best_model.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "\n",
        "# Results printing\n",
        "print(\"> Best Model Hyperparameters:\")\n",
        "print(\"> \", best_params)\n",
        "print(\"> Accuracy on Training Set: {:.2f}%\".format(train_accuracy * 100))\n",
        "\n",
        "# Results printing\n",
        "print(\"\\nResults for Test Set:\")\n",
        "print(\"=====================\")\n",
        "for params, mean_score, std_score in zip(grid_search.cv_results_['params'], grid_search.cv_results_['mean_test_score'], grid_search.cv_results_['std_test_score']):\n",
        "    print(\"Kernel: {}, C: {}, Gamma: {}\".format(params['kernel'], params['C'], params.get('gamma', 'N/A')))\n",
        "    print(\"Accuracy: {:.2f}% (+/- {:.2f}%)\".format(mean_score * 100, std_score * 100))\n",
        "    print()\n",
        "\n",
        "# Find the best model and parameters for the Testing Set\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Results printing\n",
        "print(\"> Best Model Hyperparameters:\")\n",
        "print(\"> \", best_params)\n",
        "print(\"> Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))"
      ],
      "metadata": {
        "id": "b9LKLfoRc5b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "30,000 images were selected as the training dataset for the model, and correspondingly, 10,000 images for testing, due to the significantly long execution time of the code (>12 hours) and resource usage limit on GColab for 60,000 images as the training dataset. Since even with 30,000 images, the execution takes approximately 2 hours, the printed results are as follows:\n",
        "\n",
        "Results for the Training Set:\n",
        "========================\n",
        "Kernel: linear, C: 0.1, Gamma: N/A\n",
        "Accuracy: 93.59% (+/- 0.37%)\n",
        "\n",
        "Kernel: linear, C: 1, Gamma: N/A\n",
        "Accuracy: 92.26% (+/- 0.53%)\n",
        "\n",
        "Kernel: linear, C: 10, Gamma: N/A\n",
        "Accuracy: 91.44% (+/- 0.53%)\n",
        "\n",
        "Kernel: rbf, C: 0.1, Gamma: 0.1\n",
        "Accuracy: 40.90% (+/- 0.69%)\n",
        "\n",
        "Kernel: rbf, C: 0.1, Gamma: 0.01\n",
        "Accuracy: 93.34% (+/- 0.20%)\n",
        "\n",
        "Kernel: rbf, C: 0.1, Gamma: 0.001\n",
        "Accuracy: 87.12% (+/- 0.30%)\n",
        "\n",
        "Kernel: rbf, C: 1, Gamma: 0.1\n",
        "Accuracy: 90.69% (+/- 0.26%)\n",
        "\n",
        "Kernel: rbf, C: 1, Gamma: 0.01\n",
        "Accuracy: 96.33% (+/- 0.15%)\n",
        "\n",
        "Kernel: rbf, C: 1, Gamma: 0.001\n",
        "Accuracy: 92.25% (+/- 0.41%)\n",
        "\n",
        "Kernel: rbf, C: 10, Gamma: 0.1\n",
        "Accuracy: 91.23% (+/- 0.22%)\n",
        "\n",
        "Kernel: rbf, C: 10, Gamma: 0.01\n",
        "Accuracy: 97.36% (+/- 0.19%)\n",
        "\n",
        "Kernel: rbf, C: 10, Gamma: 0.001\n",
        "Accuracy: 94.39% (+/- 0.31%)\n",
        "\n",
        "> Best Model Hyperparameters:\n",
        "> {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
        "> Accuracy on the Training Set: 99.98%\n",
        "\n",
        "Results for the Test Set:\n",
        "=====================\n",
        "Kernel: linear, C: 0.1, Gamma: N/A\n",
        "Accuracy: 93.59% (+/- 0.37%)\n",
        "\n",
        "Kernel: linear, C: 1, Gamma: N/A\n",
        "Accuracy: 92.26% (+/- 0.53%)\n",
        "\n",
        "Kernel: linear, C: 10, Gamma: N/A\n",
        "Accuracy: 91.44% (+/- 0.53%)\n",
        "\n",
        "Kernel: rbf, C: 0.1, Gamma: 0.1\n",
        "Accuracy: 40.90% (+/- 0.69%)\n",
        "\n",
        "Kernel: rbf, C: 0.1, Gamma: 0.01\n",
        "Accuracy: 93.34% (+/- 0.20%)\n",
        "\n",
        "Kernel: rbf, C: 0.1, Gamma: 0.001\n",
        "Accuracy: 87.12% (+/- 0.30%)\n",
        "\n",
        "Kernel: rbf, C: 1, Gamma: 0.1\n",
        "Accuracy: 90.69% (+/- 0.26%)\n",
        "\n",
        "Kernel: rbf, C: 1, Gamma: 0.01\n",
        "Accuracy: 96.33% (+/- 0.15%)\n",
        "\n",
        "Kernel: rbf, C: 1, Gamma: 0.001\n",
        "Accuracy: 92.25% (+/- 0.41%)\n",
        "\n",
        "Kernel: rbf, C: 10, Gamma: 0.1\n",
        "Accuracy: 91.23% (+/- 0.22%)\n",
        "\n",
        "Kernel: rbf, C: 10, Gamma: 0.01\n",
        "Accuracy: 97.36% (+/- 0.19%)\n",
        "\n",
        "Kernel: rbf, C: 10, Gamma: 0.001\n",
        "Accuracy: 94.39% (+/- 0.31%)\n",
        "\n",
        "> Best Model Hyperparameters:\n",
        "> {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
        "> Accuracy on the Test Set: 97.55%\n",
        "\n",
        "We observe that the success rates of the RBF model, even with 30,000 training images, are very high (~97-99%). Therefore, if we choose more training samples (60,000), this success rate can only increase, but without significantly changing the already obtained result."
      ],
      "metadata": {
        "id": "VsIUWOQhWFkY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**3) Image classification after PCA and using SVMs**"
      ],
      "metadata": {
        "id": "VK_7yWT3ZGQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "conserved_variances = [0.90, 0.85, 0.80]\n",
        "\n",
        "for variance in conserved_variances:\n",
        "    print(\"Conserved Variance: {:.2f}\".format(variance))\n",
        "\n",
        "    # Apply PCA with various 'conserved variance' values\n",
        "    pca = PCA(n_components=variance)\n",
        "    X_train_pca = pca.fit_transform(X_train)\n",
        "\n",
        "    # SVM classifier init\n",
        "    svm = SVC(C=10, gamma=0.01, kernel='rbf')\n",
        "\n",
        "    # Timer start\n",
        "    start_time = time.time()\n",
        "\n",
        "    # SVM fitting on the training data\n",
        "    svm.fit(X_train_pca, y_train)\n",
        "\n",
        "    # Timer stop and elapsed time calculation\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    # Transform of the testing data with the same PCA\n",
        "    X_test_pca = pca.transform(X_test)\n",
        "\n",
        "    # Predictions of the model on the testing data\n",
        "    y_pred = svm.predict(X_test_pca)\n",
        "\n",
        "    # Accuracy calculation\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    print(\"Data Components Preserved: {}\".format(pca.n_components_))\n",
        "    print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "    print(\"Elapsed Time: {:.2f} seconds\".format(elapsed_time))\n",
        "    print(\"-----------------------------------\\n\")"
      ],
      "metadata": {
        "id": "KF-US8yHeSFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* When selecting a large number of dimensions for analysis, there is a risk of providing \"too many\" reference points and analyses to the model, potentially leading to an inability to draw accurate conclusions due to \"overfitting.\" On the other hand, if we provide too few reference points/dimensions, the model will have insufficient data, leading to deviations due to \"data starvation.\"\n",
        "\n",
        "* Additionally, when aiming for higher accuracy in results, it requires more execution time, and when the model operates in higher dimensions, data analysis also takes more time.\n",
        "\n",
        "* Therefore, it is necessary to initially choose an appropriate number of dimensions to avoid \"overfitting\" and \"data starvation.\" Furthermore, depending on the requirements of the problem we want to solve, we choose whether to emphasize accuracy or execution speed."
      ],
      "metadata": {
        "id": "Yr0yGzDmnkk0"
      }
    }
  ]
}